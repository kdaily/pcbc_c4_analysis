"""This only runs on belltown/sodo, a Sage Bionetworks cluster.

"""

import os
import csv
import glob
import numpy as np
import pandas as pd

# # For running synapse client, which requires python 2
# PY2VIRTENV = "/home/ubuntu/.virtualenvs/python2/bin/activate"

# Files are linked from here into the local input directory
# /external-data/DAT_114__PCBC_Data/mRNA/GO-Elite/GO_Elite_output/GO-Elite_results/CompleteResults/ORA/archived-20150520-045614

INPUT_DIR = './input'

INPUT_FILES = glob.glob("%s/*.txt" % INPUT_DIR)

# Not sure what these are.
INPUT_FILES = filter(lambda x: not x.startswith("GeneNames"), INPUT_FILES)

vars = list(map(lambda x: os.path.basename(x).split(".txt")[0].split("-"), INPUT_FILES))

contrasts = set([x[0] for x in vars])

# Not using all genesets b/c GO headers are different than the rest
genesets = set([x[1] for x in vars if x[1] != 'GO'])

rule all:
    input:
        './output/final/DiffExpr_GOElite_merged.tsv', './output/final/DiffExpr_GOElite_merged.txt'

# Concatenate all merged files together
rule concatenate_merged:
    input:
        expand('./output/merged/{contrast}-{geneset}.tsv', contrast=contrasts, geneset=genesets)
    output:
        './output/final/DiffExpr_GOElite_merged.tsv'
    run:
        with open(output[0], 'w') as out:

            d = pd.read_csv(input[0], sep="\t")

            for infile in input[1:]:
                d = d.append(pd.read_csv(infile, sep="\t"))

            d.to_csv(out, sep="\t", index=False)

# Merge the txt and association files together
rule merge_txt_association:
    input:
        txt='./output/processed/{contrast}-{geneset}.txt',
        assoc='./output/processed/{contrast}-{geneset}-associations.tab'
    output:
        merged='./output/merged/{contrast}-{geneset}.tsv'
    params: geneset='{geneset}', contrast='{contrast}'
    run:
        with open(output.merged, 'w') as out:
            txt = pd.read_csv(input.txt, sep="\t")
            assoc = pd.read_csv(input.assoc, sep="\t")
            merged = pd.merge(left=txt, right=assoc, how="left", on="Gene-Set Name")

            merged['geneset'] = [params.geneset] * merged.shape[0]
            merged['contrast'] = [params.contrast] * merged.shape[0]

            merged.to_csv(out, sep="\t", index=False)

# Process the association files, standardize the column names
rule standardize_association:
    input:
        assoc='./input/{contrast}-{geneset}-associations.tab'
    output:
        assoc='./output/processed/{contrast}-{geneset}-associations.tab'
    run:
        with open(output.assoc, 'w') as out:
            d = open(input.assoc)

            # Header line is first; replace last column with 'Gene-Set Name'
            line = d.readline().strip()

            c1, c2, c3 = line.split("\t")
            line = "\t".join([c1, c2, "Gene-Set Name"])

            print(line, file=out)

            for row in d.readlines():
                print(row.rstrip(), sep="", file=out)

# Concatenate all merged files together
rule concatenate_text:
    input:
        expand('./output/processed/{contrast}-{geneset}.txt', contrast=contrasts, geneset=genesets)
    output:
        './output/final/DiffExpr_GOElite_merged.txt'
    run:
        with open(output[0], 'w') as out:

            d = pd.read_csv(input[0], sep="\t")

            base1 = os.path.basename(input[0]).split(".txt")[0]
	    contrast, geneset = base1.split("-")
	    d["contrast"] = contrast
	    d["geneset"] = geneset

            for infile in input[1:]:
                base1 = os.path.basename(infile).split(".txt")[0]
                contrast, geneset = base1.split("-")

                tmp = pd.read_csv(infile, sep="\t")
                tmp["contrast"] = contrast
                tmp["geneset"] = geneset

                d = d.append(tmp)

            d.to_csv(out, sep="\t", index=False)

# Remove the header rows - after first blank line, data starts
rule remove_header:
    input:
        txt='./input/{contrast}-{geneset}.txt'
    output:
        txt='./output/processed/{contrast}-{geneset}.txt'
    params: batch='-pe orte 1',scratchdir="/tmp"
    threads: 1
    run:
        with open(output.txt, 'w') as out:
            d = open(input.txt)

            line = d.readline().strip()

            while not line == "":
                line = d.readline().strip()

            for row in d.readlines():
                print(row.rstrip(), sep="", file=out)
